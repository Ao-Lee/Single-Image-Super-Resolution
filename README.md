# single image super resolution

single image super resolution with perceptual and adversarial losses

###  implementation details
- Wasserstein GAN with gradient penalty is used. This is helpful for training process to converge. For more details, see [this paper](https://arxiv.org/abs/1704.00028)
- [Perceptual loss](https://arxiv.org/abs/1603.08155) is used. 
- The final loss is a weighted combination of adversarial loss, perceptual loss and L1 distance loss. I tried to remove L1 loss, but colors of the result images are no stable.
- The network is borrowed from [this paper](https://arxiv.org/abs/1609.04802). Except that the last up-sampling layer of the generator network is modified according to [this paper](https://arxiv.org/abs/1609.05158).
- Low resolution images are generated by applying cubic interpolation on original (high resolution) images.
- Traditional evaluation methods, like [PSNR](https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio) and [SSIM](https://en.wikipedia.org/wiki/Structural_similarity) are never used. Human institution is used instead to evaluate the quality of the generated images. I think these traditional metrics fail to give a valid evaluation in single image super resolution applications.
- Heavy hyper parameter tuning is not performed. So better performance is expected if parameter tuning is applied (with additional human effort to evaluate the results)

### system environment
- this project uses Keras v2.3.1 with TensorFlow v1.13.1 backend
- to simplify the implementation, the project assumes channel-last dim ordering, meaning a typical output of a layer has form: (batch, height, weight, channel)
- the model is trained on a single [GTX 1080 Ti](https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti/) graphic card, with roughly 15-25 hours.

### Applications
this application was originally designed to pre-process satellite images. However, only a part of code and results performed on COCO dataset is provided.

### Results 
here shows the validation result examples where the model was trained on [COCO dataset](http://cocodataset.org/). The first column shows the original high resolution image, the second column shows the model prediction, the third column shows the low resolution image (input image of the algorithm)

![Alt text](https://github.com/Ao-Lee/Single-Image-Super-Resolution/raw/master/Results/1.bmp)

![Alt text](https://github.com/Ao-Lee/Single-Image-Super-Resolution/raw/master/Results/2.bmp)
