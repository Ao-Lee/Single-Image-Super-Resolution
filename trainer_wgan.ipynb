{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers import BatchNormalization, LeakyReLU, Conv2D, Input\n",
    "\n",
    "from keras.applications import VGG19\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join\n",
    "import keras.backend as K\n",
    "from mydata.loader_coco import COCO\n",
    "from mydata.utils import InvertedProcess\n",
    "from mymodel.srgen import SrGen\n",
    "from mymodel.model_utils import FindLayerByName, SetTrainable\n",
    "from train_utils import SaveImgPerEpoch, Logger\n",
    "import cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetVggModel(input_shape=(384,384,3)):\n",
    "    vgg = VGG19(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "    \n",
    "    idx_f1 = FindLayerByName(vgg, 'block5_conv2')\n",
    "    out_f1 = vgg.layers[idx_f1].output\n",
    "    idx_f2 = FindLayerByName(vgg, 'block5_conv4')\n",
    "    out_f2 = vgg.layers[idx_f2].output  \n",
    "    \n",
    "    model = Model(vgg.inputs, [out_f1, out_f2])\n",
    "    SetTrainable(model, False)\n",
    "    return model\n",
    "\n",
    "def GetG(input_shape=(96,96,3)):\n",
    "    model = SrGen(input_shape=input_shape)\n",
    "    return model\n",
    "\n",
    "def GetD(input_shape=(384,384,3)):\n",
    "    def d_block(layer_input, filters, strides=1, bn=True):\n",
    "        d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
    "        d = LeakyReLU(alpha=0.2)(d)\n",
    "        if bn:\n",
    "            d = BatchNormalization(momentum=0.8)(d)\n",
    "        return d\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = d_block(inputs, 64, strides=2, bn=False)\n",
    "    x = d_block(x, 64)\n",
    "    x = d_block(x, 64, strides=2)\n",
    "    x = d_block(x, 64*2)\n",
    "    x = d_block(x, 64*2, strides=2)\n",
    "    x = d_block(x, 64*4)\n",
    "    x = d_block(x, 64*4, strides=2)\n",
    "    x = d_block(x, 64*8)\n",
    "    x = d_block(x, 64*8, strides=2)\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    # x = Flatten()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(1, name='outputs')(x)\n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGAN_Trainer():\n",
    "    def __init__(self, loss_weights=[1, 0.1, 0.1, 0], lr=0.0001, batch=5, model_path=None):\n",
    "        '''\n",
    "        loss_weights are weights of the following losses:\n",
    "            [1] WassersteinLoss\n",
    "            [2] VGG feature mse loss \n",
    "            [3] VGG feature mse loss \n",
    "            [4] L1 loss between fake hr and real hr images (na√Øve method)\n",
    "        '''\n",
    "        self.batch = batch\n",
    "        optimizer = RMSprop(lr=lr)\n",
    "        \n",
    "        # data\n",
    "        ds = COCO(root=cfg.PATH_COCO, batch_size=batch, shape_lr=cfg.SIZE_LR, ratio=2)\n",
    "        self.shape_lr = ds.GetShapeLowResolution()\n",
    "        self.shape_hr = ds.GetShapeHighResolution()\n",
    "        self.data_loader = ds.GetGenerator_Tr()\n",
    "\n",
    "        # model-vgg\n",
    "        self.vgg = GetVggModel(input_shape=self.shape_hr)\n",
    "        self.vgg.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # model-D\n",
    "        self.discriminator = GetD(input_shape=self.shape_hr)\n",
    "        self.discriminator.compile(loss=self.WassersteinLoss, optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        # model-G\n",
    "        self.generator = GetG(input_shape=self.shape_lr)\n",
    "        if model_path: self.generator.load_weights(os.path.join(cfg.PATH_MODEL, model_path))\n",
    "\n",
    "        # model_combine\n",
    "        img_lr = Input(shape=self.shape_lr)\n",
    "        fake_hr = self.generator(img_lr)\n",
    "        vgg_features = self.vgg(fake_hr)\n",
    "        vgg_feature_0 = vgg_features[0]\n",
    "        vgg_feature_1 = vgg_features[1]\n",
    "\n",
    "        SetTrainable(self.discriminator, False)\n",
    "        distance_w = self.discriminator(fake_hr)\n",
    "\n",
    "        self.combined = Model(img_lr, [distance_w, vgg_feature_0, vgg_feature_1, fake_hr])\n",
    "        self.combined.compile(loss=[self.WassersteinLoss, 'mean_squared_error', 'mean_squared_error', 'mean_absolute_error'], loss_weights=loss_weights, optimizer=optimizer)\n",
    "\n",
    "        # others\n",
    "        self.label_neg = -np.ones((self.batch, 1))\n",
    "        self.label_pos = np.ones((self.batch, 1))\n",
    "        self.logger = Logger('train_log.txt')\n",
    "        \n",
    "    def WassersteinLoss(self, y_true, y_pred):\n",
    "        return K.mean(y_true * y_pred)\n",
    "    \n",
    "    def TrainD(self, clip_value):\n",
    "        imgs_lr, imgs_hr = next(self.data_loader)\n",
    "        fake_hr = self.generator.predict(imgs_lr)\n",
    "        result_real = self.discriminator.train_on_batch(imgs_hr, self.label_neg)\n",
    "        d_loss_real = result_real[0]\n",
    "        result_fake = self.discriminator.train_on_batch(fake_hr, self.label_pos)\n",
    "        d_loss_fake = result_fake[0]\n",
    "            \n",
    "        # clip weights\n",
    "        for l in self.discriminator.layers:\n",
    "            weights = l.get_weights()\n",
    "            weights = [np.clip(w, -clip_value, clip_value) for w in weights]\n",
    "            l.set_weights(weights)\n",
    "                \n",
    "        d_loss = d_loss_fake + d_loss_real\n",
    "        info_d = 'dloss:{:.5f}\\tdreal:{:.5f}\\tdfake:{:.5f}'.format(d_loss, d_loss_real, d_loss_fake)\n",
    "        return info_d\n",
    "            \n",
    "    def TrainG(self):\n",
    "        imgs_lr, imgs_hr = next(self.data_loader)\n",
    "        features = self.vgg.predict(imgs_hr)\n",
    "        result = self.combined.train_on_batch(imgs_lr, [self.label_neg, features[0], features[1], imgs_hr])\n",
    "        # result = [round(num, 3) for num in list(result)]\n",
    "        info_g = 'total:{:.2f}\\tWasserstein:{:.5f}\\tvgg:{:.2f}\\tvgg:{:.2f}\\tpixel:{:.3f}'.format(result[0], result[1], result[2], result[3], result[4])\n",
    "        return info_g\n",
    "            \n",
    "    def Train(self, \n",
    "              epoches=30000,  # total number of epoches\n",
    "              report_interval=50,  # save models & pics every report_interval epoches\n",
    "              save_dir='results',   # directory to save models & pics\n",
    "              clip_value = 0.01,    # clip value applied on gradient of the D net\n",
    "              ):\n",
    "              \n",
    "        for epoch in range(epoches):\n",
    "            n_critic = 20 if epoch % 200 == 0 else 5\n",
    "            for epoch_critic in range(n_critic):\n",
    "                info_d = self.TrainD(clip_value=clip_value)\n",
    "                info_d = 'Epoch:{}'.format(epoch)+'\\t'+info_d\n",
    "                if epoch_critic % 10 == 0 and epoch_critic != 0: self.logger.LogAndPrint(info_d)\n",
    "                \n",
    "            info_g = self.TrainG()\n",
    "            info_g = 'Epoch:{}'.format(epoch)+'\\t'+info_g\n",
    "            \n",
    "            if epoch % report_interval != 0: continue\n",
    "            self.logger.LogAndPrint(info_d)\n",
    "            self.logger.LogAndPrint(info_g)\n",
    "\n",
    "            imgs_lr, imgs_hr = next(self.data_loader)\n",
    "            fake_hr = self.generator.predict(imgs_lr)\n",
    "            list_imgs = [fake_hr, imgs_hr, imgs_lr]\n",
    "            \n",
    "            list_imgs = [InvertedProcess(img) for img in list_imgs]\n",
    "            list_names = ['Generated', 'HR Img', 'LR Img']\n",
    "            epoch_current_str = format(epoch, '05d')\n",
    "            filename = 'wgan_pic_epoch{}.png'.format(epoch_current_str)\n",
    "            SaveImgPerEpoch(list_imgs, list_names, save_dir, filename)\n",
    "            filename = 'wgan_model_epoch{}.hdf5'.format(epoch_current_str)\n",
    "            self.generator.save_weights(join(save_dir, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/liao/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model_path = None\n",
    "trainer = WGAN_Trainer(lr=0.0002, loss_weights=[1, 0.02, 0.25, 0.005], batch=4, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {}\n",
    "train_params['epoches'] = 50000\n",
    "train_params['report_interval'] = 500\n",
    "train_params['save_dir'] = 'results'\n",
    "train_params['clip_value'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/liao/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch:0\tdloss:0.00096\tdreal:-0.00106\tdfake:0.00202\n",
      "Epoch:0\tdloss:0.00104\tdreal:-0.00098\tdfake:0.00202\n",
      "Epoch:0\ttotal:0.05\tWasserstein:-0.00097\tvgg:1.40\tvgg:0.09\tpixel:0.612\n",
      "Epoch:200\tdloss:0.00021\tdreal:-0.00027\tdfake:0.00049\n",
      "Epoch:400\tdloss:0.00021\tdreal:-0.00027\tdfake:0.00049\n",
      "Epoch:500\tdloss:0.00022\tdreal:-0.00027\tdfake:0.00049\n",
      "Epoch:500\ttotal:0.01\tWasserstein:-0.00027\tvgg:0.24\tvgg:0.01\tpixel:0.123\n",
      "Epoch:600\tdloss:0.00022\tdreal:-0.00027\tdfake:0.00049\n",
      "Epoch:800\tdloss:0.00021\tdreal:-0.00027\tdfake:0.00049\n",
      "Epoch:1000\tdloss:0.00022\tdreal:-0.00027\tdfake:0.00049\n",
      "Epoch:1000\tdloss:0.00021\tdreal:-0.00027\tdfake:0.00048\n",
      "Epoch:1000\ttotal:0.01\tWasserstein:-0.00027\tvgg:0.36\tvgg:0.02\tpixel:0.133\n",
      "Epoch:1200\tdloss:0.00021\tdreal:-0.00027\tdfake:0.00049\n"
     ]
    }
   ],
   "source": [
    "trainer.Train(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
