from keras.layers import Dense, GlobalAveragePooling2D, Flatten, Dropout
from keras.layers import BatchNormalization, LeakyReLU, Conv2D, Input

from keras.applications import VGG16
from keras.models import Model
from keras.optimizers import RMSprop

import numpy as np
import os
from os.path import join
from functools import reduce
from operator import mul
import keras.backend as K
from mydata.loader_div2k import DIV2K
from mydata.utils import InvertedProcess
from mymodel.srgen import SrGen
from mymodel.model_utils import FindLayerByName, SetTrainable
from train_utils import SaveImgPerEpoch, Logger
import cfg

def FeatLoss(y_true, y_pred):
    '''
    y_true: vgg features derived from a batch of images generated by the Generator (B, h, w, c)
    y_pred: vgg features derived from a batch of HR images (B, h, w, c)
    Feature Reconstruction Loss
    See: Perceptual Losses for Real-Time Style Transfer and Super-Resolution
    '''
    shape = K.int_shape(y_pred)                         # (B, h, w, c)
    axis = list(range(len(shape)))[1:]                  # [1, 2, 3]
    coef = reduce(mul, shape[1:], 1)
    diff = K.square(y_true - y_pred)                    # (B, h, w, c)
    diff_norm = K.sqrt(K.sum(diff, axis=axis)) / coef   # (B, )
    return K.mean(diff_norm)
    
def GetVggModel(input_shape=(384,384,3)):
    vgg = VGG16(input_shape=input_shape, weights='imagenet', include_top=False)
    
    idx_f1 = FindLayerByName(vgg, 'block2_conv2')
    out_f1 = vgg.layers[idx_f1].output
    idx_f2 = FindLayerByName(vgg, 'block3_conv3')
    out_f2 = vgg.layers[idx_f2].output  
    
    model = Model(vgg.inputs, [out_f1, out_f2])
    SetTrainable(model, False)
    return model

def GetG(input_shape=(96,96,3)):
    model = SrGen(input_shape=input_shape)
    return model

def GetD(input_shape=(384,384,3)):
    def d_block(layer_input, filters, strides=1, bn=True):
        d = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)
        d = LeakyReLU(alpha=0.2)(d)
        if bn:
            d = BatchNormalization(momentum=0.8)(d)
        return d

    inputs = Input(shape=input_shape)
    x = d_block(inputs, 64, strides=2, bn=False)
    x = d_block(x, 64)
    x = d_block(x, 64, strides=2)
    x = d_block(x, 64*2)
    x = d_block(x, 64*2, strides=2)
    x = d_block(x, 64*4)
    x = d_block(x, 64*4, strides=2)
    x = d_block(x, 64*8)
    x = d_block(x, 64*8, strides=2)
    x = GlobalAveragePooling2D(name='avg_pool')(x)
    # x = Flatten()(x)
    x = Dropout(0.2)(x)
    outputs = Dense(1, name='outputs')(x)
    return Model(inputs, outputs)
    
class WGAN_Trainer():
    def __init__(self, loss_weights=[1, 0.1, 0.1, 0], lr=0.0001, batch=5, model_path=None):
        '''
        loss_weights are weights of the following losses:
            [1] WassersteinLoss
            [2] VGG feature reconstruction loss 
            [3] VGG feature reconstruction loss 
            [4] L1 loss between fake hr and real hr images (na√Øve method)
        '''
        self.batch = batch
        optimizer = RMSprop(lr=lr)
        
        # data
        ds = DIV2K(root=cfg.PATH_DIV2K, batch_size=batch, size_lr=cfg.SIZE_LR)
        self.shape_lr = ds.GetShapeLowResolution()
        self.shape_hr = ds.GetShapeHighResolution()
        self.data_loader = ds.GetGenerator_Tr()

        # model-vgg
        self.vgg = GetVggModel(input_shape=self.shape_hr)
        self.vgg.compile(loss=FeatLoss, optimizer=optimizer)

        # model-D
        self.discriminator = GetD(input_shape=self.shape_hr)
        self.discriminator.compile(loss=self.WassersteinLoss, optimizer=optimizer, metrics=['accuracy'])
        
        # model-G
        self.generator = GetG(input_shape=self.shape_lr)
        if model_path: self.generator.load_weights(os.path.join(cfg.PATH_MODEL, model_path))

        # model_combine
        img_lr = Input(shape=self.shape_lr)
        fake_hr = self.generator(img_lr)
        vgg_features = self.vgg(fake_hr)
        vgg_feature_0 = vgg_features[0]
        vgg_feature_1 = vgg_features[1]

        SetTrainable(self.discriminator, False)
        distance_w = self.discriminator(fake_hr)

        self.combined = Model(img_lr, [distance_w, vgg_feature_0, vgg_feature_1, fake_hr])
        self.combined.compile(loss=[self.WassersteinLoss, FeatLoss, FeatLoss, 'mean_absolute_error'], loss_weights=loss_weights, optimizer=optimizer)

        # others
        self.label_neg = -np.ones((self.batch, 1))
        self.label_pos = np.ones((self.batch, 1))
        self.logger = Logger('train_log.txt')
        
    def WassersteinLoss(self, y_true, y_pred):
        return K.mean(y_true * y_pred)
    
    def TrainD(self, clip_value):
        imgs_lr, imgs_hr = next(self.data_loader)
        fake_hr = self.generator.predict(imgs_lr)
        result_real = self.discriminator.train_on_batch(imgs_hr, self.label_neg)
        d_loss_real = result_real[0]
        result_fake = self.discriminator.train_on_batch(fake_hr, self.label_pos)
        d_loss_fake = result_fake[0]
            
        # clip weights
        for l in self.discriminator.layers:
            weights = l.get_weights()
            weights = [np.clip(w, -clip_value, clip_value) for w in weights]
            l.set_weights(weights)
                
        d_loss = d_loss_fake + d_loss_real
        info_d = 'dloss:{:.5f}\tdreal:{:.5f}\tdfake:{:.5f}'.format(d_loss, d_loss_real, d_loss_fake)
        return info_d
            
    def TrainG(self):
        imgs_lr, imgs_hr = next(self.data_loader)
        features = self.vgg.predict(imgs_hr)
        result = self.combined.train_on_batch(imgs_lr, [self.label_neg, features[0], features[1], imgs_hr])
        # result = [round(num, 3) for num in list(result)]
        info_g = 'total:{:.4f}\tWasserstein:{:.4f}\tvgg:{:.4f}\tvgg:{:.4f}\tpixel:{:.3f}'.format(result[0], result[1], result[2], result[3], result[4])
        return info_g
            
    def Train(self, 
              epoches=30000,  # total number of epoches
              report_interval=50,  # save models & pics every report_interval epoches
              save_dir='results',   # directory to save models & pics
              clip_value = 0.01,    # clip value applied on gradient of the D net
              ):
              
        for epoch in range(epoches + 1):
            n_critic = 100 if epoch % 200 == 0 else 1
            for epoch_critic in range(n_critic):
                info_d = self.TrainD(clip_value=clip_value)
                info_d = 'Epoch:{}'.format(epoch)+'\t'+info_d
                if epoch_critic % 10 == 0 and epoch_critic != 0: self.logger.LogAndPrint(info_d)
                
            info_g = self.TrainG()
            info_g = 'Epoch:{}'.format(epoch)+'\t'+info_g
            
            if epoch % report_interval != 0: continue
            self.logger.LogAndPrint(info_d)
            self.logger.LogAndPrint(info_g)

            imgs_lr, imgs_hr = next(self.data_loader)
            fake_hr = self.generator.predict(imgs_lr)
            list_imgs = [fake_hr, imgs_hr, imgs_lr]
            
            list_imgs = [InvertedProcess(img) for img in list_imgs]
            list_names = ['Generated', 'HR Img', 'LR Img']
            epoch_current_str = format(epoch, '05d')
            filename = 'wgan_pic_epoch{}.png'.format(epoch_current_str)
            SaveImgPerEpoch(list_imgs, list_names, save_dir, filename)
            filename = 'wgan_model_epoch{}.hdf5'.format(epoch_current_str)
            self.generator.save_weights(join(save_dir, filename))
                
if __name__ == '__main__':
    K.clear_session()
    
    model_path = 'sisr_96_srgan_pretrained_mse.hdf5'
    model_path = None
    trainer = WGAN_Trainer(lr=0.001, loss_weights=[1, 1, 0.2, 0.001], batch=4, model_path=model_path)
    train_params = {}
    train_params['epoches'] = 30000
    train_params['report_interval'] = 500   
    train_params['save_dir'] = 'results_v2'
    train_params['clip_value'] = 0.01
    # trainer.Train(**train_params)
    

    